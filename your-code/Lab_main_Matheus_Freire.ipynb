{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Export Files \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0 - Accessing our database\n",
    "Create a connection to access the sakila database with the ip, user and password provided in class. Take a look at the data. Do some joins in order to have more elaborated tables in a dataframe (you can try first the query in the DBMS and then use it in your notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import getpass\n",
    "import mysql.connector\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnx = mysql.connector.connect(user ='root',\n",
    "                            password = password,\n",
    "                            host = 'localhost',\n",
    "                            database = 'sakila',\n",
    "                            auth_plugin = 'mysql_native_password')\n",
    "cnx.is_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysql.connector.cursor_cext.CMySQLCursor at 0x19b66dc8c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = cnx.cursor()\n",
    "cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT * FROM sakila.actor;'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'SELECT * FROM sakila.actor;'\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sakila = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'PENELOPE', 'GUINESS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (2, 'NICK', 'WAHLBERG', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (3, 'ED', 'CHASE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (4, 'JENNIFER', 'DAVIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (5, 'JOHNNY', 'LOLLOBRIGIDA', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (6, 'BETTE', 'NICHOLSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (7, 'GRACE', 'MOSTEL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (8, 'MATTHEW', 'JOHANSSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (9, 'JOE', 'SWANK', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (10, 'CHRISTIAN', 'GABLE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (11, 'ZERO', 'CAGE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (12, 'KARL', 'BERRY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (13, 'UMA', 'WOOD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (14, 'VIVIEN', 'BERGEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (15, 'CUBA', 'OLIVIER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (16, 'FRED', 'COSTNER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (17, 'HELEN', 'VOIGHT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (18, 'DAN', 'TORN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (19, 'BOB', 'FAWCETT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (20, 'LUCILLE', 'TRACY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (21, 'KIRSTEN', 'PALTROW', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (22, 'ELVIS', 'MARX', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (23, 'SANDRA', 'KILMER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (24, 'CAMERON', 'STREEP', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (25, 'KEVIN', 'BLOOM', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (26, 'RIP', 'CRAWFORD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (27, 'JULIA', 'MCQUEEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (28, 'WOODY', 'HOFFMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (29, 'ALEC', 'WAYNE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (30, 'SANDRA', 'PECK', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (31, 'SISSY', 'SOBIESKI', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (32, 'TIM', 'HACKMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (33, 'MILLA', 'PECK', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (34, 'AUDREY', 'OLIVIER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (35, 'JUDY', 'DEAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (36, 'BURT', 'DUKAKIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (37, 'VAL', 'BOLGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (38, 'TOM', 'MCKELLEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (39, 'GOLDIE', 'BRODY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (40, 'JOHNNY', 'CAGE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (41, 'JODIE', 'DEGENERES', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (42, 'TOM', 'MIRANDA', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (43, 'KIRK', 'JOVOVICH', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (44, 'NICK', 'STALLONE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (45, 'REESE', 'KILMER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (46, 'PARKER', 'GOLDBERG', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (47, 'JULIA', 'BARRYMORE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (48, 'FRANCES', 'DAY-LEWIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (49, 'ANNE', 'CRONYN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (50, 'NATALIE', 'HOPKINS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (51, 'GARY', 'PHOENIX', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (52, 'CARMEN', 'HUNT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (53, 'MENA', 'TEMPLE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (54, 'PENELOPE', 'PINKETT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (55, 'FAY', 'KILMER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (56, 'DAN', 'HARRIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (57, 'JUDE', 'CRUISE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (58, 'CHRISTIAN', 'AKROYD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (59, 'DUSTIN', 'TAUTOU', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (60, 'HENRY', 'BERRY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (61, 'CHRISTIAN', 'NEESON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (62, 'JAYNE', 'NEESON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (63, 'CAMERON', 'WRAY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (64, 'RAY', 'JOHANSSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (65, 'ANGELA', 'HUDSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (66, 'MARY', 'TANDY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (67, 'JESSICA', 'BAILEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (68, 'RIP', 'WINSLET', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (69, 'KENNETH', 'PALTROW', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (70, 'MICHELLE', 'MCCONAUGHEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (71, 'ADAM', 'GRANT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (72, 'SEAN', 'WILLIAMS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (73, 'GARY', 'PENN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (74, 'MILLA', 'KEITEL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (75, 'BURT', 'POSEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (76, 'ANGELINA', 'ASTAIRE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (77, 'CARY', 'MCCONAUGHEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (78, 'GROUCHO', 'SINATRA', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (79, 'MAE', 'HOFFMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (80, 'RALPH', 'CRUZ', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (81, 'SCARLETT', 'DAMON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (82, 'WOODY', 'JOLIE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (83, 'BEN', 'WILLIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (84, 'JAMES', 'PITT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (85, 'MINNIE', 'ZELLWEGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (86, 'GREG', 'CHAPLIN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (87, 'SPENCER', 'PECK', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (88, 'KENNETH', 'PESCI', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (89, 'CHARLIZE', 'DENCH', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (90, 'SEAN', 'GUINESS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (91, 'CHRISTOPHER', 'BERRY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (92, 'KIRSTEN', 'AKROYD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (93, 'ELLEN', 'PRESLEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (94, 'KENNETH', 'TORN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (95, 'DARYL', 'WAHLBERG', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (96, 'GENE', 'WILLIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (97, 'MEG', 'HAWKE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (98, 'CHRIS', 'BRIDGES', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (99, 'JIM', 'MOSTEL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (100, 'SPENCER', 'DEPP', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (101, 'SUSAN', 'DAVIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (102, 'WALTER', 'TORN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (103, 'MATTHEW', 'LEIGH', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (104, 'PENELOPE', 'CRONYN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (105, 'SIDNEY', 'CROWE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (106, 'GROUCHO', 'DUNST', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (107, 'GINA', 'DEGENERES', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (108, 'WARREN', 'NOLTE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (109, 'SYLVESTER', 'DERN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (110, 'SUSAN', 'DAVIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (111, 'CAMERON', 'ZELLWEGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (112, 'RUSSELL', 'BACALL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (113, 'MORGAN', 'HOPKINS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (114, 'MORGAN', 'MCDORMAND', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (115, 'HARRISON', 'BALE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (116, 'DAN', 'STREEP', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (117, 'RENEE', 'TRACY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (118, 'CUBA', 'ALLEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (119, 'WARREN', 'JACKMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (120, 'PENELOPE', 'MONROE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (121, 'LIZA', 'BERGMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (122, 'SALMA', 'NOLTE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (123, 'JULIANNE', 'DENCH', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (124, 'SCARLETT', 'BENING', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (125, 'ALBERT', 'NOLTE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (126, 'FRANCES', 'TOMEI', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (127, 'KEVIN', 'GARLAND', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (128, 'CATE', 'MCQUEEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (129, 'DARYL', 'CRAWFORD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (130, 'GRETA', 'KEITEL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (131, 'JANE', 'JACKMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (132, 'ADAM', 'HOPPER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (133, 'RICHARD', 'PENN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (134, 'GENE', 'HOPKINS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (135, 'RITA', 'REYNOLDS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (136, 'ED', 'MANSFIELD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (137, 'MORGAN', 'WILLIAMS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (138, 'LUCILLE', 'DEE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (139, 'EWAN', 'GOODING', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (140, 'WHOOPI', 'HURT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (141, 'CATE', 'HARRIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (142, 'JADA', 'RYDER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (143, 'RIVER', 'DEAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (144, 'ANGELA', 'WITHERSPOON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (145, 'KIM', 'ALLEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (146, 'ALBERT', 'JOHANSSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (147, 'FAY', 'WINSLET', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (148, 'EMILY', 'DEE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (149, 'RUSSELL', 'TEMPLE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (150, 'JAYNE', 'NOLTE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (151, 'GEOFFREY', 'HESTON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (152, 'BEN', 'HARRIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (153, 'MINNIE', 'KILMER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (154, 'MERYL', 'GIBSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (155, 'IAN', 'TANDY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (156, 'FAY', 'WOOD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (157, 'GRETA', 'MALDEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (158, 'VIVIEN', 'BASINGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (159, 'LAURA', 'BRODY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (160, 'CHRIS', 'DEPP', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (161, 'HARVEY', 'HOPE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (162, 'OPRAH', 'KILMER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (163, 'CHRISTOPHER', 'WEST', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (164, 'HUMPHREY', 'WILLIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (165, 'AL', 'GARLAND', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (166, 'NICK', 'DEGENERES', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (167, 'LAURENCE', 'BULLOCK', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (168, 'WILL', 'WILSON', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (169, 'KENNETH', 'HOFFMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (170, 'MENA', 'HOPPER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (171, 'OLYMPIA', 'PFEIFFER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (172, 'GROUCHO', 'WILLIAMS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (173, 'ALAN', 'DREYFUSS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (174, 'MICHAEL', 'BENING', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (175, 'WILLIAM', 'HACKMAN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (176, 'JON', 'CHASE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (177, 'GENE', 'MCKELLEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (178, 'LISA', 'MONROE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (179, 'ED', 'GUINESS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (180, 'JEFF', 'SILVERSTONE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (181, 'MATTHEW', 'CARREY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (182, 'DEBBIE', 'AKROYD', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (183, 'RUSSELL', 'CLOSE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (184, 'HUMPHREY', 'GARLAND', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (185, 'MICHAEL', 'BOLGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (186, 'JULIA', 'ZELLWEGER', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (187, 'RENEE', 'BALL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (188, 'ROCK', 'DUKAKIS', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (189, 'CUBA', 'BIRCH', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (190, 'AUDREY', 'BAILEY', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (191, 'GREGORY', 'GOODING', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (192, 'JOHN', 'SUVARI', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (193, 'BURT', 'TEMPLE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (194, 'MERYL', 'ALLEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (195, 'JAYNE', 'SILVERSTONE', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (196, 'BELA', 'WALKEN', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (197, 'REESE', 'WEST', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (198, 'MARY', 'KEITEL', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (199, 'JULIA', 'FAWCETT', datetime.datetime(2006, 2, 15, 4, 34, 33)),\n",
       " (200, 'THORA', 'TEMPLE', datetime.datetime(2006, 2, 15, 4, 34, 33))]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sakila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['actor',\n",
       " 'actor_info',\n",
       " 'address',\n",
       " 'category',\n",
       " 'city',\n",
       " 'country',\n",
       " 'customer',\n",
       " 'customer_list',\n",
       " 'film',\n",
       " 'film_actor',\n",
       " 'film_category',\n",
       " 'film_list',\n",
       " 'film_text',\n",
       " 'inventory',\n",
       " 'language',\n",
       " 'nicer_but_slower_film_list',\n",
       " 'payment',\n",
       " 'rental',\n",
       " 'sales_by_film_category',\n",
       " 'sales_by_store',\n",
       " 'staff',\n",
       " 'staff_list',\n",
       " 'store']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor = pd.DataFrame(sakila)\n",
    "cursor.execute(\"SHOW TABLES;\")\n",
    "tables = cursor.fetchall()\n",
    "tables_name = [table[0] for table in tables]\n",
    "tables_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT * FROM film''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "films = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>A Epic Drama of a Feminist And a Mad Scientist...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>86</td>\n",
       "      <td>20.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>{Behind the Scenes, Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACE GOLDFINGER</td>\n",
       "      <td>A Astounding Epistle of a Database Administrat...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>48</td>\n",
       "      <td>12.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Deleted Scenes, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ADAPTATION HOLES</td>\n",
       "      <td>A Astounding Reflection of a Lumberjack And a ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>2.99</td>\n",
       "      <td>50</td>\n",
       "      <td>18.99</td>\n",
       "      <td>NC-17</td>\n",
       "      <td>{Deleted Scenes, Trailers}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AFFAIR PREJUDICE</td>\n",
       "      <td>A Fanciful Documentary of a Frisbee And a Lumb...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>117</td>\n",
       "      <td>26.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Commentaries, Behind the Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AFRICAN EGG</td>\n",
       "      <td>A Fast-Paced Documentary of a Pastry Chef And ...</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>2.99</td>\n",
       "      <td>130</td>\n",
       "      <td>22.99</td>\n",
       "      <td>G</td>\n",
       "      <td>{Deleted Scenes}</td>\n",
       "      <td>2006-02-15 05:03:42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1                                                  2   \\\n",
       "0   1  ACADEMY DINOSAUR  A Epic Drama of a Feminist And a Mad Scientist...   \n",
       "1   2    ACE GOLDFINGER  A Astounding Epistle of a Database Administrat...   \n",
       "2   3  ADAPTATION HOLES  A Astounding Reflection of a Lumberjack And a ...   \n",
       "3   4  AFFAIR PREJUDICE  A Fanciful Documentary of a Frisbee And a Lumb...   \n",
       "4   5       AFRICAN EGG  A Fast-Paced Documentary of a Pastry Chef And ...   \n",
       "\n",
       "     3   4     5   6     7    8      9      10  \\\n",
       "0  2006   1  None   6  0.99   86  20.99     PG   \n",
       "1  2006   1  None   3  4.99   48  12.99      G   \n",
       "2  2006   1  None   7  2.99   50  18.99  NC-17   \n",
       "3  2006   1  None   5  2.99  117  26.99      G   \n",
       "4  2006   1  None   6  2.99  130  22.99      G   \n",
       "\n",
       "                                    11                  12  \n",
       "0  {Behind the Scenes, Deleted Scenes} 2006-02-15 05:03:42  \n",
       "1           {Deleted Scenes, Trailers} 2006-02-15 05:03:42  \n",
       "2           {Deleted Scenes, Trailers} 2006-02-15 05:03:42  \n",
       "3    {Commentaries, Behind the Scenes} 2006-02-15 05:03:42  \n",
       "4                     {Deleted Scenes} 2006-02-15 05:03:42  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film_df = pd.DataFrame(films)\n",
    "film_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1 - Working with JSON files\n",
    "Import the pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, load the data in nasa.json in the data folder and load it into a pandas dataframe. Name the dataframe nasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa = pd.read_json(\"nasa.json\")\n",
    "nasa = pd.DataFrame(nasa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have loaded the data, let's examine it using the head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>:@computed_region_cbhk_fwbd</th>\n",
       "      <th>:@computed_region_nnqa_25f4</th>\n",
       "      <th>fall</th>\n",
       "      <th>geolocation</th>\n",
       "      <th>id</th>\n",
       "      <th>mass</th>\n",
       "      <th>name</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [6.08333, 50....</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Aachen</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>1880-01-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [10.23333, 56...</td>\n",
       "      <td>2</td>\n",
       "      <td>720.0</td>\n",
       "      <td>Aarhus</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>1951-01-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-113, 54.216...</td>\n",
       "      <td>6</td>\n",
       "      <td>107000.0</td>\n",
       "      <td>Abee</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>1952-01-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-99.9, 16.88...</td>\n",
       "      <td>10</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>Acapulco</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>1976-01-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fell</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [-64.95, -33....</td>\n",
       "      <td>370</td>\n",
       "      <td>780.0</td>\n",
       "      <td>Achiras</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>1902-01-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   :@computed_region_cbhk_fwbd  :@computed_region_nnqa_25f4  fall  \\\n",
       "0                          NaN                          NaN  Fell   \n",
       "1                          NaN                          NaN  Fell   \n",
       "2                          NaN                          NaN  Fell   \n",
       "3                          NaN                          NaN  Fell   \n",
       "4                          NaN                          NaN  Fell   \n",
       "\n",
       "                                         geolocation   id      mass      name  \\\n",
       "0  {'type': 'Point', 'coordinates': [6.08333, 50....    1      21.0    Aachen   \n",
       "1  {'type': 'Point', 'coordinates': [10.23333, 56...    2     720.0    Aarhus   \n",
       "2  {'type': 'Point', 'coordinates': [-113, 54.216...    6  107000.0      Abee   \n",
       "3  {'type': 'Point', 'coordinates': [-99.9, 16.88...   10    1914.0  Acapulco   \n",
       "4  {'type': 'Point', 'coordinates': [-64.95, -33....  370     780.0   Achiras   \n",
       "\n",
       "  nametype     recclass    reclat    reclong                     year  \n",
       "0    Valid           L5  50.77500    6.08333  1880-01-01T00:00:00.000  \n",
       "1    Valid           H6  56.18333   10.23333  1951-01-01T00:00:00.000  \n",
       "2    Valid          EH4  54.21667 -113.00000  1952-01-01T00:00:00.000  \n",
       "3    Valid  Acapulcoite  16.88333  -99.90000  1976-01-01T00:00:00.000  \n",
       "4    Valid           L6 -33.16667  -64.95000  1902-01-01T00:00:00.000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasa.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The value_counts() function is commonly used in pandas to find the frequency of every value in a column.\n",
    "\n",
    "In the cell below, use the value_counts() function to determine the frequency of all types of asteroid landings by applying the function to the fall column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1521209299.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Matheus Freire\\AppData\\Local\\Temp\\ipykernel_9148\\1521209299.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    mkdir \"data\"\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "nasa['fall'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save the dataframe as a json file again. Save the dataframe using the orient=records argument and name the file nasa-output.json. Remember to save the file inside the data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file data already exists.\n"
     ]
    }
   ],
   "source": [
    "mkdir \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa.to_json(\"data/nasa-output.json\", orient = 'records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 2 - Working with CSV and Other Separated Files\n",
    "\n",
    "Import the pandas library\n",
    "\n",
    "csv files are more commonly used as dataframes. In the cell below, load the file from the URL provided using the `read_csv()` function in pandas. Starting version 0.19 of pandas, you can load a csv file into a dataframe directly from a URL without having to load the file first like we did with the JSON URL. The dataset we will be using contains informtaions about NASA shuttles. \n",
    "\n",
    "In the cell below, we define the column names and the URL of the data. Following this cell, read the tst file to a variable called `shuttle`. Since the file does not contain the column names, you must add them yourself using the column names declared in `cols` using the `names` argument. Additionally, a tst file is space separated, make sure you pass ` sep=' '` to the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your pandas import here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code:\n",
    "\n",
    "cols = ['time', 'rad_flow', 'fpv_close', 'fpv_open', 'high', 'bypass', 'bpv_close', 'bpv_open', 'class']\n",
    "tst_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/shuttle/shuttle.tst'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuttle = pd.read_csv(tst_url, sep = \" \", names = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that this worked by looking at the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>rad_flow</th>\n",
       "      <th>fpv_close</th>\n",
       "      <th>fpv_open</th>\n",
       "      <th>high</th>\n",
       "      <th>bypass</th>\n",
       "      <th>bpv_close</th>\n",
       "      <th>bpv_open</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>-4</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-1</td>\n",
       "      <td>89</td>\n",
       "      <td>-7</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>-2</td>\n",
       "      <td>25</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>-6</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    time  rad_flow  fpv_close  fpv_open  high  bypass  bpv_close  bpv_open  \\\n",
       "55     0        81          0        -6    11      25         88        64   \n",
       "56     0        96          0        52    -4      40         44         4   \n",
       "50    -1        89         -7        50     0      39         40         2   \n",
       "53     9        79          0        42    -2      25         37        12   \n",
       "55     2        82          0        54    -6      26         28         2   \n",
       "\n",
       "    class  \n",
       "55      4  \n",
       "56      4  \n",
       "50      1  \n",
       "53      4  \n",
       "55      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuttle.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make life easier for us, let's turn this dataframe into a comma separated file by saving it using the `to_csv()` function. Save `shuttle` into the file `shuttle.csv` and ensure the file is comma separated and that we are not saving the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuttle.to_csv(\"data/shuttle.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 3 - Working with Excel Files\n",
    "\n",
    "We can also use pandas to convert excel spreadsheets to dataframes. Let's use the `read_excel()` function. In this case, `astronauts.xls` is in the same folder that contains this notebook. Read this file into a variable called `astronaut`. \n",
    "\n",
    "Note: Make sure to install the `xlrd` library if it is not yet installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd\n",
    "astronaut = pd.read_excel(\"astronauts.xls\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `head()` function to inspect the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Group</th>\n",
       "      <th>Status</th>\n",
       "      <th>Birth Date</th>\n",
       "      <th>Birth Place</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Alma Mater</th>\n",
       "      <th>Undergraduate Major</th>\n",
       "      <th>Graduate Major</th>\n",
       "      <th>Military Rank</th>\n",
       "      <th>Military Branch</th>\n",
       "      <th>Space Flights</th>\n",
       "      <th>Space Flight (hr)</th>\n",
       "      <th>Space Walks</th>\n",
       "      <th>Space Walks (hr)</th>\n",
       "      <th>Missions</th>\n",
       "      <th>Death Date</th>\n",
       "      <th>Death Mission</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Joseph M. Acaba</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Active</td>\n",
       "      <td>1967-05-17</td>\n",
       "      <td>Inglewood, CA</td>\n",
       "      <td>Male</td>\n",
       "      <td>University of California-Santa Barbara; Univer...</td>\n",
       "      <td>Geology</td>\n",
       "      <td>Geology</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3307</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>STS-119 (Discovery), ISS-31/32 (Soyuz)</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loren W. Acton</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Retired</td>\n",
       "      <td>1936-03-07</td>\n",
       "      <td>Lewiston, MT</td>\n",
       "      <td>Male</td>\n",
       "      <td>Montana State University; University of Colorado</td>\n",
       "      <td>Engineering Physics</td>\n",
       "      <td>Solar Physics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STS 51-F (Challenger)</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James C. Adamson</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>1946-03-03</td>\n",
       "      <td>Warsaw, NY</td>\n",
       "      <td>Male</td>\n",
       "      <td>US Military Academy; Princeton University</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>Aerospace Engineering</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Army (Retired)</td>\n",
       "      <td>2</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>STS-28 (Columbia), STS-43 (Atlantis)</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thomas D. Akers</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>1951-05-20</td>\n",
       "      <td>St. Louis, MO</td>\n",
       "      <td>Male</td>\n",
       "      <td>University of Missouri-Rolla</td>\n",
       "      <td>Applied Mathematics</td>\n",
       "      <td>Applied Mathematics</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Air Force (Retired)</td>\n",
       "      <td>4</td>\n",
       "      <td>814</td>\n",
       "      <td>4</td>\n",
       "      <td>29.0</td>\n",
       "      <td>STS-41 (Discovery), STS-49 (Endeavor), STS-61 ...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Buzz Aldrin</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Retired</td>\n",
       "      <td>1930-01-20</td>\n",
       "      <td>Montclair, NJ</td>\n",
       "      <td>Male</td>\n",
       "      <td>US Military Academy; MIT</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Astronautics</td>\n",
       "      <td>Colonel</td>\n",
       "      <td>US Air Force (Retired)</td>\n",
       "      <td>2</td>\n",
       "      <td>289</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Gemini 12, Apollo 11</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name    Year  Group   Status Birth Date    Birth Place Gender  \\\n",
       "0   Joseph M. Acaba  2004.0   19.0   Active 1967-05-17  Inglewood, CA   Male   \n",
       "1    Loren W. Acton     NaN    NaN  Retired 1936-03-07   Lewiston, MT   Male   \n",
       "2  James C. Adamson  1984.0   10.0  Retired 1946-03-03     Warsaw, NY   Male   \n",
       "3   Thomas D. Akers  1987.0   12.0  Retired 1951-05-20  St. Louis, MO   Male   \n",
       "4       Buzz Aldrin  1963.0    3.0  Retired 1930-01-20  Montclair, NJ   Male   \n",
       "\n",
       "                                          Alma Mater     Undergraduate Major  \\\n",
       "0  University of California-Santa Barbara; Univer...                 Geology   \n",
       "1   Montana State University; University of Colorado     Engineering Physics   \n",
       "2          US Military Academy; Princeton University             Engineering   \n",
       "3                       University of Missouri-Rolla     Applied Mathematics   \n",
       "4                           US Military Academy; MIT  Mechanical Engineering   \n",
       "\n",
       "          Graduate Major Military Rank         Military Branch  Space Flights  \\\n",
       "0                Geology           NaN                     NaN              2   \n",
       "1          Solar Physics           NaN                     NaN              1   \n",
       "2  Aerospace Engineering       Colonel       US Army (Retired)              2   \n",
       "3    Applied Mathematics       Colonel  US Air Force (Retired)              4   \n",
       "4           Astronautics       Colonel  US Air Force (Retired)              2   \n",
       "\n",
       "   Space Flight (hr)  Space Walks  Space Walks (hr)  \\\n",
       "0               3307            2              13.0   \n",
       "1                190            0               0.0   \n",
       "2                334            0               0.0   \n",
       "3                814            4              29.0   \n",
       "4                289            2               8.0   \n",
       "\n",
       "                                            Missions Death Date Death Mission  \n",
       "0             STS-119 (Discovery), ISS-31/32 (Soyuz)        NaT           NaN  \n",
       "1                              STS 51-F (Challenger)        NaT           NaN  \n",
       "2               STS-28 (Columbia), STS-43 (Atlantis)        NaT           NaN  \n",
       "3  STS-41 (Discovery), STS-49 (Endeavor), STS-61 ...        NaT           NaN  \n",
       "4                               Gemini 12, Apollo 11        NaT           NaN  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astronaut.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `value_counts()` function to find the most popular undergraduate major among all astronauts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Physics'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MostPopular_undregrad = astronaut['Undergraduate Major'].value_counts().idxmax()\n",
    "MostPopular_undregrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to all the commas present in the cells of this file, let's save it as a tab separated csv file. In the cell below, save `astronaut` as a tab separated file using the `to_csv` function. Call the file `astronaut.csv` and remember to remove the index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "astronaut.to_csv(\"data/astronaut.csv\", sep = \"\\t\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge - Fertility Dataset\n",
    "\n",
    "Visit the following [URL](https://archive.ics.uci.edu/ml/datasets/Fertility) and retrieve the dataset as well as the column headers. Determine the correct separator and read the file into a variable called `fertility`. Examine the dataframe using the `head()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
